# Exploring Non-Contrastive Language-Image Pre-Training with xCLIP

Official PyTorch implementation and pre-trained models for paper **Non-Contrastive Learning Meets Language-Image Pre-Training**.

[[`arXiv`](https://arxiv.org/abs/2210.09304)] [[`BibTex`](https://github.com/shallowtoil/xclip#citing-xclip)]


## News :tada:
- Update - The code and pre-trained models are on the way.
- Feburary 2023 - The paper is accepted by CVPR 2023.
- Octorber 2022 - Release the pre-print on [arXiv](https://arxiv.org/abs/2210.09304).

## Citing xCLIP
If you find this repository useful, please consider giving a star :star: and citation:
```
@article{zhou2022non,
  title={Non-Contrastive Learning Meets Language-Image Pre-Training},
  author={Zhou, Jinghao and Dong, Li and Gan, Zhe and Wang, Lijuan and Wei, Furu},
  journal={Computer Vision and Pattern Recognition (CVPR)},
  year={2023}
}
```
